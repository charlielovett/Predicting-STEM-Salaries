{
 "cells": [
  {
   "cell_type": "raw",
   "id": "33dd6c4c",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Project Report\"\n",
    "subtitle: LCJJ\n",
    "author: Charlie Lovett, Jacob Muriel, Lainey Neild, and Jack Troxel\n",
    "date: 05/23/2023\n",
    "number-sections: true\n",
    "abstract: _This project focuses on the development of a model to predict salaries in STEM fields. In this project, the optimization metric used was Mean Absolute Error. An MAE on testing data of ~47,000 was achieved using the following models and ensembling techniques: Ridge, Lasso, Random Forest, AdaBoost, Gradient Boosting, and XGBoost. Based on this model, stakeholders including students and employers can more accurately predict salaries to correctly value work and avoid overcompensating employees_.\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    self-contained: true\n",
    "    font-size: 100%\n",
    "    toc-depth: 4\n",
    "    mainfont: serif\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0116f49b",
   "metadata": {},
   "source": [
    "## Background / Motivation\n",
    "\n",
    "All four of us are current college students that will soon be entering the professional world. Many of us are planning to pursue careers in various STEM fields such as software development or data science. With this in mind, we wanted to create a model that can help to predict the salaries of the people that work in these fields. Through this project, we wanted to develop a model that we could one day use to predict what our salaries should be. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ff1421",
   "metadata": {},
   "source": [
    "## Problem statement \n",
    "\n",
    "Through this project, we will attempt to predict the salaries for employees that work in STEM fields. As we are predicting salaries, the response observed in this project is a continuous variableâ€”their annunal salary in USD. We will assess our model accuracy using MAE. We have selected this metric instead of RMSE as there is no inherit risk or disadvantage in incorrectly predicting observations by a large margin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c7b95f",
   "metadata": {},
   "source": [
    "## Data sources\n",
    "\n",
    "We will be using a data source comprised of salary data for employees in STEM fields. This dataset was found on Kaggle and contains data scraped from a salary collecting website (levels.fyi). The data can be found [here](https://www.kaggle.com/datasets/jackogozaly/data-science-and-stem-salaries). \n",
    "\n",
    "The response in this problem is `totalyearlycompensation`. Some of the predictors include `company`, `title`, `yearsofexperience`, `yearsatcompany`, `location`, `Education`, `Race`, and `Gender`.\n",
    "\n",
    "There are ~21,000 observations in our dataset. There are 10 total predictors comprised of 2 continuous and 8 categorical predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c255035",
   "metadata": {},
   "source": [
    "## Stakeholders\n",
    "\n",
    "The dataset our group has chosen to analyze investigates the compensation for various STEM roles at companies. Many groups of people could benefit from this analysis. Firstly, students pursuing a career in STEM would definitely be interested in this data. Although compensation does not drive most student's professional path, it certainly is a factor that holds weight. Secondly, colleges and universities would benefit from our group's analysis. By understanding which roles are in the highest demand in our society, they may place more emphasis on prioritizing resources and professors in those academic areas. Thirdly, employees would be interested in our findings to ensure that their compensation is fair relative to industry standards, giving them the opportunity to negotiate for higher pay. Fourthly, in the same way our analysis could benefit employees, employers would benefit as they could see how their compensation packages compare to their competitor's compensation packages allowing them to understand better how they are attracting talent in these fields and how to make the open positions more attractive to prospective employees. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7ea9bb",
   "metadata": {},
   "source": [
    "## Data quality check / cleaning / preparation \n",
    "\n",
    "Show the distribution of the response here. Report the standard deviation and mean in case of a regression problem, and proportion of 0s and 1s in case of classification.\n",
    "\n",
    "For all other content, as mentioned below, just provide the highlights *(if any)* and put the details in the appendix.\n",
    "\n",
    "In a tabular form, show the distribution of values of each variable used in the analysis - for both categorical and continuous variables. Distribution of a categorical variable must include the number of missing values, the number of unique values, the frequency of all its levels. If a categorical variable has too many levels, you may just include the counts of the top 3-5 levels. \n",
    "\n",
    "Mention any useful insights you obtained from the data quality check that helped you develop the model or helped you realize the necessary data cleaning / preparation. Its ok if there were none.\n",
    "\n",
    "Were there any potentially incorrect values of variables that required cleaning? If yes, how did you clean them? Were there missing values? How did you handle them? Its ok if the data was already clean.\n",
    "\n",
    "Did you do any data wrangling or data preparation before the data was ready to use for model development? Did you create any new predictors from exisiting predictors? For example, if you have number of transactions and spend in a credit card dataset, you may create spend per transaction for predicting if a customer pays their credit card bill. Mention the steps at a broad level, you may put minor details in the appendix. Only mention the steps that ended up being useful towards developing your model(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb11c9b",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bd74a9",
   "metadata": {},
   "source": [
    "If there is any EDA that helped with model development, put it here. If EDA didn't help then mention that, and you may show your EDA effort *(if any)* in the appendix.\n",
    "\n",
    "List the insights (as bullet points), if any, you got from EDA  that ended up being useful towards developing your final model. \n",
    "\n",
    "If there are too many plots / tables, you may put them into appendix, and just mention the insights you got from them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f12d5d",
   "metadata": {},
   "source": [
    "Note that you can write code to publish the results of the code, but hide the code using the yaml setting `#|echo: false`. For example, the code below makes a plot, but the code itself is not published with Quarto in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14a59729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| echo: false\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(10));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39c782c",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "What kind of a models did you use? What performance metric(s) did you optimize and why?\n",
    "\n",
    "Is there anything unorthodox / new in your approach? \n",
    "\n",
    "What problems did you anticipate? What problems did you encounter? \n",
    "\n",
    "Did your problem already have solution(s) (posted on Kaggle or elsewhere). If yes, then how did you build upon those solutions, what did you do differently? Is your model better as compared to those solutions in terms of prediction accuracy or your chosen metric?\n",
    "\n",
    "**Important: Mention any code repositories (with citations) or other sources that you used, and specifically what changes you made to them for your project.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acab331a",
   "metadata": {},
   "source": [
    "## Developing the model: Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ec4c9",
   "metadata": {},
   "source": [
    "Every person must describe their hyperparameter tuning procedure. Show the grid of hyperparameter values over which the initial search was done *(you may paste your grid search / random search / any other search code)*, and the optimal hyperparameter values obtained. After getting the initial search results, how did you make decisions *(if any)* to further fine-tune your model. Did you do another grid / random search or did you tune hyperparameters sequentially? If you think you didn't need any fine tuning after the initial results, then mention that and explain why.\n",
    "\n",
    "Put each model in a section of its name and mention the name of the team-member tuning the model. Below is an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea422beb",
   "metadata": {},
   "source": [
    "### Lasso & Ridge\n",
    "*By Charlie Lovett*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78fbd0e",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "*By Lainey Neild*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2916849c",
   "metadata": {},
   "source": [
    "### AdaBoost\n",
    "*By Jacob Muriel*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f552ef",
   "metadata": {},
   "source": [
    "### Gradient Boosting & XGBoost\n",
    "*By Jack Troxel*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d2996f",
   "metadata": {},
   "source": [
    "I used extremely similar processes to tune both Gradient Boosting and XGBoost. For both, I started with an extremely coarse gridsearch using RandomizedSearchCV based on the results of an exploration into each hyperparameter value versus the corresponding cross validation MAE. After that, I conducted I finer search using GridSearchCV. I continued to narrow in on finer and finer parameters until I found that the optimal parameters from these searches were actually increasing MAE on test data (due to overfitting). The searches that I conducted and the results that I achieved are seen below. As seen, I did not include n_estimators in any of my searches. Instead, I tuned n_estimators individually after deciding upon the other optimal hyperparameters.\n",
    "\n",
    "Initial Gradient Boosting Search (RandomizedSearchCV):\n",
    "- grid['learning_rate'] = [0.0001, 0.001, 0.01,0.1, 1.0]\n",
    "- grid['max_depth'] = [5,6,7,8,9,10,11,12]\n",
    "- grid['subsample'] = [0.25, 0.5, 0.75, 1]\n",
    "\n",
    "Gradient Boosting Optimal Hyperparameters (after multiple rounds of finer tuning): \n",
    "- learning_rate = 0.1\n",
    "- subsample = 0.75\n",
    "- max_depth = 6\n",
    "- n_estimators = 450\n",
    "\n",
    "*Gradient Boosting MAE on Test Data: 47,579*\n",
    "\n",
    "Initial XGBoost Search (RandomizedSearchCV):\n",
    "- grid['max_depth'] = [3,4,5,6,7,8],\n",
    "- grid['learning_rate'] = [0.1,0.2,0.3],\n",
    "- grid['reg_lambda'] = [2, 10],\n",
    "- grid['gamma'] = [0, 10],\n",
    "- grid['subsample'] = [0.25,0.5,0.75,1]\n",
    "\n",
    "XGBoost Optimal Hyperparameters (after multiple rounds of finer tuning):\n",
    "- max_depth = 6\n",
    "- learning_rate = 0.08\n",
    "- reg_lambda = 10\n",
    "- gamma = 0\n",
    "- subsample = 0.75\n",
    "- n_estimators = 450\n",
    "\n",
    "*XGBoost MAE on Test Data: 47,440*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dedee2",
   "metadata": {},
   "source": [
    "## Model Ensemble "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa68b0a5",
   "metadata": {},
   "source": [
    "Put the results of enembling individual models. Feel free to add subsections in this section to add more innovative ensembling methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c5924a",
   "metadata": {},
   "source": [
    "### Voting ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a31cb2",
   "metadata": {},
   "source": [
    "The simplest voting ensemble will be the model where all models have equal weights.\n",
    "\n",
    "You may come up with innovative methods of estimating weights of the individual models, such as based on their cross-val error. Sometimes, these methods may work better than stacking ensembles, as stacking ensembles tend to overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcff4cda",
   "metadata": {},
   "source": [
    "### Stacking ensemble\n",
    "Try out different models as the metamodel. You may split work as follows. The person who worked on certain types of models *(say AdaBoost and MARS)* also uses those models as a metamodel in the stacking ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b22a5f3",
   "metadata": {},
   "source": [
    "### Ensemble of ensembled models\n",
    "\n",
    "If you are creating multiple stacking ensembles *(based on different metamodels)*, you may ensemble them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fe5f5f",
   "metadata": {},
   "source": [
    "### Innovative ensembling methods\n",
    "*(Optional)*\n",
    "\n",
    "Some models may do better on certain subsets of the predictor space. You may find that out, and given a data point, choose the model(s) that will best predict for that data point. This is similar to the idea of developing a decision tree metamodel. However, decision tree is prone to overfitting.\n",
    "\n",
    "Another idea may be to correct the individual models with the intercept and slope *(note the tree-based models don't have an intercept and may suffer from a constant bias)*, and then ensemble them. This is equivalent to having a simple linear regression meta-model for each of the individual models, and then ensembling the meta-models with a meta-metamodel or a voting ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b46343d",
   "metadata": {},
   "source": [
    "## Limitations of the model with regard to prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85ead90",
   "metadata": {},
   "source": [
    "Are you confident that you found the optimal hyperparameter values for each of your individual models, and that your individual models cannot be better tuned? Or, are there any models that could be better tuned if you had more time / resources, but you are limited by the amount of time you can spend on the course project *(equivalent to one assignment)*? If yes, then which models could be better tuned and how?\n",
    "\n",
    "Will it be possible / convenient / expensive for the stakeholders to collect the data relating to the predictors in the model. Using your model, how soon will the stakeholder be able to predict the outcome before the outcome occurs. For example, if the model predicts the number of bikes people will rent in Evanston on a certain day, then how many days before that day will your model be able to make the prediction. This will depend on how soon the data that your model uses becomes available. If you are predicting election results, how many days / weeks / months / years before the election can you predict the results. \n",
    "\n",
    "When will your model become too obsolete to be useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02ffcf3",
   "metadata": {},
   "source": [
    "We are fairly confident in our chosen hyperparameters. While we did have a large dataset with a large amount of dummy variables, we still were able to perform effective grid searches to gauge the hyperparameter space with regards to our model's accuracy. That said, we obviously did not check every single combination of hyperparameters so it is definitely possible that there are better selections, and given some more time and computational power we likely could have achieved marginally better results. Additionally, it should not be too difficult for the stakeholders to collect relevant data relating to the predictors in the model. Individual students and employees should be aware of their own identities and the characteristics of their jobs (or prospective jobs) which is all they would need to use the model, and employers should have all the same information on their own employees to be used in the same way. It might be a bit more difficult for universities to track where their students typically work after studying or where their current students are likely to go, though they probably do have some of the relevant information on hand. The model may become obsolete by the year, in which case it could simply be updated by being trained on a new dataset with updated salaries and other relevant information. Once it's updated, stakeholders should be able to use it right away to decide how to proceed with their future, though they may need to be aware that "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a185cb",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations to stakeholder(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0077a796",
   "metadata": {},
   "source": [
    "Based on the results of our model, we are beyond satisfied in our ability to predict salaries for employees in STEM fields. Our model's MAE is significantly lower than that of the intercept only model and is also significanly lower than the initial standard deviation of the response variable, and both of those indicate that our model is performing significanly better than merely predicting the mean. Additionally, our stakeholders should be able to use our model to help in the following ways. Students pursuing a career in STEM can look at their own identities and weigh those with other potential aspects (company, what title they would have, etc.) to help them decide where they might want to work. Universities are likely aware of where their students typically go after studying, and they can use this information in tendem with our model to help them decide how to allocate their resources in a way that would set their students up for the most success (financially, at least). Employees can also look at their own identities and other aspects of their job to gauge whether they are being fairly compensated, and can use this information to decide whether they want to fight for a higher compensation of even try to go to another company. Lastly, employers can use the model in a similar way to see whether they are paying their employees too much, and can use it as a reasonable basis for denying some people higher compensations. That said, the stakeholders should probably be aware of a limitation that has to do with our model. Because of the large variety of results within the categorical predictors, we had to group and convert some variable names to \"other\" so reduce the computational complexity of our model, and thus not all companies, locations, and titles are distinctly addressed in this model. Additionally, our model should likely be updated every year (with a new dataset containing data from salaries and demographics from the most recent year) to account for overarching shifts in the industry's salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca45613",
   "metadata": {},
   "source": [
    "Add details of each team member's contribution, other than the models contributed, in the table below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5505da5c",
   "metadata": {},
   "source": [
    "<html>\n",
    "<style>\n",
    "table, td, th {\n",
    "  border: 1px solid black;\n",
    "}\n",
    "\n",
    "table {\n",
    "  border-collapse: collapse;\n",
    "  width: 100%;\n",
    "}\n",
    "\n",
    "th {\n",
    "  text-align: left;\n",
    "}\n",
    "    \n",
    "\n",
    "</style>\n",
    "<body>\n",
    "\n",
    "<h2>Individual contribution</h2>\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "     <colgroup>\n",
    "       <col span=\"1\" style=\"width: 15%;\">\n",
    "       <col span=\"1\" style=\"width: 20%;\">\n",
    "       <col span=\"1\" style=\"width: 25%;\">\n",
    "       <col span=\"1\" style=\"width: 40%;\">\n",
    "    </colgroup>\n",
    "  <tr>\n",
    "    <th>Team member</th>\n",
    "    <th>Individual Model</th>\n",
    "    <th>Work other than individual model</th>    \n",
    "    <th>Details of work other than individual model</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Charlie Lovett</td>\n",
    "    <td>Lasso & Ridge</td>\n",
    "    <td>Data cleaning and Model Ensembling</td>    \n",
    "    <td>Helped to limit count of categorical observations. Led the development of ensembeled models.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Jacob Muriel</td>\n",
    "    <td>AdaBoost</td>\n",
    "    <td>Ensembling</td>    \n",
    "    <td>Led original data cleaning and assisted Charlie with ensembling.</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>Lainey Neild</td>\n",
    "    <td>Random forest</td>\n",
    "    <td>EDA and Data Preparation</td>    \n",
    "    <td>Conducted initial EDA and assisted in data preparation process.</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>Jack Troxel</td>\n",
    "    <td>XGBoost & Gradient Boosting</td>\n",
    "    <td>EDA and Presentation</td>    \n",
    "    <td>Helped with initial EDA and created presentation for final project.</td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b1cafe",
   "metadata": {},
   "source": [
    "## References {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdb1aad",
   "metadata": {},
   "source": [
    "List and number all bibliographical references. When referenced in the text, enclose the citation number in square brackets, for example [1].\n",
    "\n",
    "[1] Authors. The frobnicatable foo filter, 2014. Face and Gesture submission ID 324. Supplied as additional material\n",
    "fg324.pdf. 3\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
